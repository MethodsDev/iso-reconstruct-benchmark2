{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddbcff4-34fb-4892-a470-4b1a2bbe2851",
   "metadata": {},
   "source": [
    "#### 1. Isoseqsim - pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72b3b94-9075-4eba-ad06-c289665af9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Metrics Results:\n",
      "                         Folder        Tool      RMSE  Pearson_Correlation  \\\n",
      "0    arabidopsis_isoseqsim_e000       bambu  1.440826             0.880243   \n",
      "1    arabidopsis_isoseqsim_e000       flair  0.960735             0.943238   \n",
      "2    arabidopsis_isoseqsim_e000  gffcompare  0.893090             0.949031   \n",
      "3    arabidopsis_isoseqsim_e000    isoquant  0.957517             0.943422   \n",
      "4    arabidopsis_isoseqsim_e000   isosceles  0.740789             0.964548   \n",
      "..                          ...         ...       ...                  ...   \n",
      "115        mouse_isoseqsim_e085   lraa_0216  5.157930             0.054784   \n",
      "116        mouse_isoseqsim_e085   lraa_0223  5.157930             0.054784   \n",
      "117        mouse_isoseqsim_e085     oarfish  0.553363             0.978575   \n",
      "118        mouse_isoseqsim_e085      salmon  1.925620             0.830886   \n",
      "119        mouse_isoseqsim_e085   stringtie  4.248159             0.686186   \n",
      "\n",
      "     Spearman_Correlation  Mean_Relative_Difference  \n",
      "0                0.907602                  0.062090  \n",
      "1                0.959159                  0.022623  \n",
      "2                0.960484                  0.031949  \n",
      "3                0.959277                  0.023367  \n",
      "4                0.970167                  0.032446  \n",
      "..                    ...                       ...  \n",
      "115              0.042698                  0.999677  \n",
      "116              0.042698                  0.999677  \n",
      "117              0.976087                  0.046068  \n",
      "118              0.836421                  0.337420  \n",
      "119              0.724620                  1.291988  \n",
      "\n",
      "[120 rows x 6 columns]\n",
      "PDF with plots saved to benchmarking_results/1.isoseqsim_pb/combined_quantification_metrics_plots.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the base directory where your files are located\n",
    "base_dir = \"terra_outputs/1.isoseqsim_pb\"\n",
    "benchmarking_results_dir = \"benchmarking_results/1.isoseqsim_pb\"\n",
    "\n",
    "# Ensure the benchmarking results directory exists\n",
    "os.makedirs(benchmarking_results_dir, exist_ok=True)\n",
    "\n",
    "# Define the folders to process\n",
    "folders = [\n",
    "    \"arabidopsis_isoseqsim_e000\", \"arabidopsis_isoseqsim_e016\", \"arabidopsis_isoseqsim_e050\", \"arabidopsis_isoseqsim_e085\",\n",
    "    \"magnaporthe_isoseqsim_e000\", \"magnaporthe_isoseqsim_e016\", \"magnaporthe_isoseqsim_e050\", \"magnaporthe_isoseqsim_e085\",\n",
    "    \"mouse_isoseqsim_e000\", \"mouse_isoseqsim_e016\", \"mouse_isoseqsim_e050\", \"mouse_isoseqsim_e085\"\n",
    "]\n",
    "\n",
    "# Define the file names, methods, transcript columns, and count columns\n",
    "files = [\n",
    "    'Bambu_quant.txt', 'Flair_quant.tsv', 'Isosceles_quant.txt', 'IsoQuant_quant.tsv', \n",
    "    'Oarfish_quant.tsv', 'Salmon_quant.sf', 'StringTie_quant.csv', \n",
    "    'LRAA_0216.quant-only.quant.expr', 'LRAA_0223.quant-only.quant.expr', 'Gffcompare_OUT_expression_matrix.tsv'\n",
    "]\n",
    "\n",
    "methods = [\n",
    "    'bambu', 'flair', 'isosceles', 'isoquant',  \n",
    "    'oarfish', 'salmon', 'stringtie', \n",
    "    'lraa_0216', 'lraa_0223', 'gffcompare'\n",
    "]\n",
    "\n",
    "transcript_cols = [\n",
    "    'txname', 'ids', 'transcript_id', '#feature_id', 'tname', \n",
    "    'name', 'transcript_id', 'transcript_id', \n",
    "    'transcript_id', 'transcript_id', 'ref_id'\n",
    "]\n",
    "\n",
    "count_cols = [\n",
    "    'count', 'flair_condition1_batch1', 'count', 'count', 'num_reads', \n",
    "    'numreads', 'stringtie', 'all_reads', \n",
    "    'all_reads', 'all_reads', 'expression'\n",
    "]\n",
    "\n",
    "# Define the ground truth file paths\n",
    "groundtruth_files = {\n",
    "    'arabidopsis': 'references/1.isoseqsim_pb/Arabidopsis/Arabidopsis_transcript_id_count.tsv',\n",
    "    'magnaporthe': 'references/1.isoseqsim_pb/Magnaporthe/Magnaporthe_isoseqsim_ground_truth_transcript_id_count.tsv',\n",
    "    'mouse': 'references/1.isoseqsim_pb/Mouse/Mouse_isoseqsim_ground_truth_transcript_id_count.tsv'\n",
    "}\n",
    "\n",
    "# Function to read in a file and add a method column\n",
    "def read_file(file_name, method_name, transcript_col, count_col):\n",
    "    delim = ',' if file_name.endswith('.csv') else '\\t'\n",
    "    df = pd.read_csv(file_name, delimiter=delim)\n",
    "    df.columns = df.columns.str.lower()  # Convert column names to lowercase\n",
    "    transcript_col = transcript_col.lower()\n",
    "    count_col = count_col.lower()\n",
    "    \n",
    "    if method_name == 'bambu' or count_col not in df.columns:\n",
    "        if len(df.columns) > 2 or (method_name == 'gffcompare' and 'ref_id' in df.columns and 'expression' in df.columns):\n",
    "            count_col = 'expression' if method_name == 'gffcompare' else df.columns[2]  # Select the appropriate column\n",
    "            transcript_col = 'ref_id' if method_name == 'gffcompare' else transcript_col\n",
    "        else:\n",
    "            print(f\"File {file_name} does not have enough columns. Available columns: {df.columns}\")\n",
    "            return None\n",
    "    try:\n",
    "        df = df[[transcript_col, count_col]].rename(columns={transcript_col: 'transcript_name', count_col: 'count'})\n",
    "    except KeyError:\n",
    "        print(f\"Columns {transcript_col} and {count_col} not found in {file_name}. Available columns: {df.columns}\")\n",
    "        return None\n",
    "    df['method'] = method_name\n",
    "    return df\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(predicted, actual):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# Function to calculate Mean Relative Difference\n",
    "def calculate_mrd(predicted, actual):\n",
    "    return np.mean(np.abs(predicted - actual) / actual)\n",
    "\n",
    "# Initialize lists to collect all metrics results and merged counts\n",
    "all_metrics_results = []\n",
    "all_raw_counts = []\n",
    "\n",
    "# Process each folder\n",
    "for folder in folders:\n",
    "    quant_dir = os.path.join(base_dir, folder, \"Quant\")\n",
    "    if not os.path.exists(quant_dir):\n",
    "        continue\n",
    "    \n",
    "    # Determine the ground truth file based on the folder\n",
    "    if 'arabidopsis' in folder:\n",
    "        groundtruth_path = groundtruth_files['arabidopsis']\n",
    "    elif 'magnaporthe' in folder:\n",
    "        groundtruth_path = groundtruth_files['magnaporthe']\n",
    "    elif 'mouse' in folder:\n",
    "        groundtruth_path = groundtruth_files['mouse']\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Read the ground truth file\n",
    "    groundtruth = pd.read_csv(groundtruth_path, delimiter='\\t')\n",
    "    groundtruth = groundtruth[['transcript_id', 'count']].rename(columns={'transcript_id': 'transcript_name'})\n",
    "    groundtruth['method'] = 'groundtruth'\n",
    "    \n",
    "    # Read all quantification files\n",
    "    data_frames = []\n",
    "    for file, method, transcript_col, count_col in zip(files, methods, transcript_cols, count_cols):\n",
    "        file_path = os.path.join(quant_dir, file)\n",
    "        if os.path.exists(file_path):\n",
    "            df = read_file(file_path, method, transcript_col, count_col)\n",
    "            if df is not None:\n",
    "                data_frames.append(df)\n",
    "    \n",
    "    # Combine all data frames into one\n",
    "    if data_frames:\n",
    "        data = pd.concat(data_frames)\n",
    "        all_data = pd.concat([groundtruth, data])\n",
    "        all_data.fillna(0, inplace=True)\n",
    "        \n",
    "        # Ensure the count column contains only numeric values\n",
    "        all_data['count'] = pd.to_numeric(all_data['count'], errors='coerce').fillna(0)\n",
    "        \n",
    "        # Store raw counts for combined_merged_counts.tsv\n",
    "        raw_data = all_data.pivot(index='transcript_name', columns='method', values='count').fillna(0)\n",
    "        raw_data['Folder'] = folder\n",
    "        all_raw_counts.append(raw_data)\n",
    "        \n",
    "        all_data['count'] = np.log2(all_data['count'] + 1)\n",
    "        \n",
    "        # Reshape the data to wide format\n",
    "        all_data_wide = all_data.pivot(index='transcript_name', columns='method', values='count')\n",
    "        all_data_wide = all_data_wide[all_data_wide['groundtruth'].notna()]\n",
    "        \n",
    "        merged_data = all_data_wide.fillna(0)\n",
    "        \n",
    "        # Calculate metrics for each column against groundtruth, excluding non-numeric columns\n",
    "        for column_name in merged_data.columns:\n",
    "            if column_name != 'groundtruth':\n",
    "                rmse_value = calculate_rmse(merged_data[column_name], merged_data['groundtruth'])\n",
    "                pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
    "                spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
    "                mrd_value = calculate_mrd(merged_data[column_name], merged_data['groundtruth'])\n",
    "                all_metrics_results.append({\n",
    "                    'Folder': folder,\n",
    "                    'Tool': column_name,\n",
    "                    'RMSE': rmse_value,\n",
    "                    'Pearson_Correlation': pearson_value,\n",
    "                    'Spearman_Correlation': spearman_value,\n",
    "                    'Mean_Relative_Difference': mrd_value\n",
    "                })\n",
    "\n",
    "# Convert the collected metrics results to a DataFrame\n",
    "all_metrics_results_df = pd.DataFrame(all_metrics_results)\n",
    "\n",
    "# Save the combined metrics results to a TSV file\n",
    "combined_metrics_results_path = os.path.join(benchmarking_results_dir, 'combined_quantification_metrics_results.tsv')\n",
    "all_metrics_results_df.to_csv(combined_metrics_results_path, sep='\\t', index=False)\n",
    "\n",
    "# Combine all raw counts into a single DataFrame\n",
    "all_raw_counts_df = pd.concat(all_raw_counts)\n",
    "\n",
    "# Save the combined raw counts to a TSV file\n",
    "combined_merged_counts_path = os.path.join(benchmarking_results_dir, 'combined_quantification_merged_counts.tsv')\n",
    "all_raw_counts_df.to_csv(combined_merged_counts_path, sep='\\t')\n",
    "\n",
    "# Print the combined metrics results\n",
    "print(\"Combined Metrics Results:\")\n",
    "print(all_metrics_results_df)\n",
    "\n",
    "# Generate PDF with plots\n",
    "pdf_path = os.path.join(benchmarking_results_dir, 'combined_quantification_metrics_plots.pdf')\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for folder in folders:\n",
    "        folder_data = all_metrics_results_df[all_metrics_results_df['Folder'] == folder]\n",
    "        \n",
    "        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "        fig.suptitle(f'Metrics for {folder}', fontsize=16)\n",
    "        \n",
    "        # Sort data for plotting\n",
    "        folder_data_rmse = folder_data.sort_values(by='RMSE')\n",
    "        folder_data_mrd = folder_data.sort_values(by='Mean_Relative_Difference')\n",
    "        folder_data_pearson = folder_data.sort_values(by='Pearson_Correlation', ascending=False)\n",
    "        folder_data_spearman = folder_data.sort_values(by='Spearman_Correlation', ascending=False)\n",
    "        \n",
    "        # RMSE plot\n",
    "        axs[1, 0].bar(folder_data_rmse['Tool'], folder_data_rmse['RMSE'])\n",
    "        axs[1, 0].set_title('RMSE')\n",
    "        axs[1, 0].set_xticks(range(len(folder_data_rmse['Tool'])))\n",
    "        axs[1, 0].set_xticklabels(folder_data_rmse['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Pearson Correlation plot\n",
    "        axs[0, 0].bar(folder_data_pearson['Tool'], folder_data_pearson['Pearson_Correlation'])\n",
    "        axs[0, 0].set_title('Pearson Correlation')\n",
    "        axs[0, 0].set_xticks(range(len(folder_data_pearson['Tool'])))\n",
    "        axs[0, 0].set_xticklabels(folder_data_pearson['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Spearman Correlation plot\n",
    "        axs[0, 1].bar(folder_data_spearman['Tool'], folder_data_spearman['Spearman_Correlation'])\n",
    "        axs[0, 1].set_title('Spearman Correlation')\n",
    "        axs[0, 1].set_xticks(range(len(folder_data_spearman['Tool'])))\n",
    "        axs[0, 1].set_xticklabels(folder_data_spearman['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Mean Relative Difference plot\n",
    "        axs[1, 1].bar(folder_data_mrd['Tool'], folder_data_mrd['Mean_Relative_Difference'])\n",
    "        axs[1, 1].set_title('Mean Relative Difference')\n",
    "        axs[1, 1].set_xticks(range(len(folder_data_mrd['Tool'])))\n",
    "        axs[1, 1].set_xticklabels(folder_data_mrd['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"PDF with plots saved to {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df173a06-2372-42ee-8f64-152a3eb1cc5b",
   "metadata": {},
   "source": [
    "#### SIRVs - pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68db00c7-f278-482a-ac7a-49078f774fa4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:160: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
      "/var/tmp/ipykernel_377369/462205455.py:161: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Metrics Results:\n",
      "               Folder        Tool      RMSE  Pearson_Correlation  \\\n",
      "0    CL_BT474_E0_sirv       bambu  2.802756                  NaN   \n",
      "1    CL_BT474_E0_sirv       flair  2.699533                  NaN   \n",
      "2    CL_BT474_E0_sirv  gffcompare  1.429335                  NaN   \n",
      "3    CL_BT474_E0_sirv    isoquant  2.046609                  NaN   \n",
      "4    CL_BT474_E0_sirv   isosceles  2.974661                  NaN   \n",
      "..                ...         ...       ...                  ...   \n",
      "103   CL_UHRR_E2_sirv   isosceles  3.221857             0.574289   \n",
      "104   CL_UHRR_E2_sirv   lraa_0223  1.315622             0.858178   \n",
      "105   CL_UHRR_E2_sirv     oarfish  1.793809             0.749296   \n",
      "106   CL_UHRR_E2_sirv      salmon  3.083520             0.444839   \n",
      "107   CL_UHRR_E2_sirv   stringtie  5.636042             0.371968   \n",
      "\n",
      "     Spearman_Correlation  Mean_Relative_Difference  \n",
      "0                     NaN                  0.126136  \n",
      "1                     NaN                  0.124181  \n",
      "2                     NaN                  0.077495  \n",
      "3                     NaN                  0.100036  \n",
      "4                     NaN                  0.142751  \n",
      "..                    ...                       ...  \n",
      "103              0.733376                  0.160126  \n",
      "104              0.856705                  0.078518  \n",
      "105              0.801228                  0.113215  \n",
      "106              0.462438                  0.248882  \n",
      "107              0.588211                  0.481921  \n",
      "\n",
      "[108 rows x 6 columns]\n",
      "PDF with plots saved to benchmarking_results/2.sirvs_pb/combined_quantification_metrics_plots.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the base directory where your files are located\n",
    "base_dir = \"terra_outputs/2.sirvs_pb\"\n",
    "benchmarking_results_dir = \"benchmarking_results/2.sirvs_pb\"\n",
    "\n",
    "# Ensure the benchmarking results directory exists\n",
    "os.makedirs(benchmarking_results_dir, exist_ok=True)\n",
    "\n",
    "# Define the folders to process\n",
    "folders = [\n",
    "    \"CL_BT474_E0_sirv\", \"CL_BT474_E1_sirv\", \"CL_BT474_E2_sirv\",\n",
    "    \"CL_HG002_E0_sirv\", \"CL_HG002_E1_sirv\", \"CL_HG002_E2_sirv\",\n",
    "    \"CL_K562_E0_sirv\", \"CL_K562_E1_sirv\", \"CL_K562_E2_sirv\",\n",
    "    \"CL_UHRR_E0_sirv\", \"CL_UHRR_E1_sirv\", \"CL_UHRR_E2_sirv\"\n",
    "]\n",
    "\n",
    "# Define the file names, methods, transcript columns, and count columns\n",
    "files = [\n",
    "    'Bambu_quant.txt', 'Flair_quant.tsv', 'Isosceles_quant.txt', 'IsoQuant_quant.tsv', \n",
    "    'Oarfish_quant.tsv', 'Salmon_quant.sf', 'StringTie_quant.csv', \n",
    "    'LRAA_0223.quant-only.quant.expr', \n",
    "    'Gffcompare_OUT_expression_matrix.tsv'\n",
    "]\n",
    "\n",
    "methods = [\n",
    "    'bambu', 'flair', 'isosceles', 'isoquant', \n",
    "    'oarfish', 'salmon', 'stringtie', \n",
    "    'lraa_0223', \n",
    "    'gffcompare'\n",
    "]\n",
    "\n",
    "transcript_cols = [\n",
    "    'txname', 'ids', 'transcript_id', '#feature_id', 'tname', \n",
    "    'name', 'transcript_id', 'transcript_id', \n",
    "    'transcript_id', \n",
    "    'ref_id'\n",
    "]\n",
    "\n",
    "count_cols = [\n",
    "    '', 'flair_condition1_batch1', 'count', 'count', 'num_reads', \n",
    "    'numreads', 'stringtie', 'all_reads', \n",
    "    'all_reads', \n",
    "    'expression'\n",
    "]\n",
    "\n",
    "# Define the ground truth file paths\n",
    "groundtruth_files = {\n",
    "    'CL_BT474_E0_sirv': 'BT474_E0_merged_sirv_sorted_groundtruth_E0.tsv',\n",
    "    'CL_BT474_E1_sirv': 'BT474_E1_merged_sirv_sorted_groundtruth_E1.tsv',\n",
    "    'CL_BT474_E2_sirv': 'BT474_E2_merged_sirv_sorted_groundtruth_E2.tsv',\n",
    "    'CL_HG002_E0_sirv': 'HG002_E0_merged_sirv_sorted_groundtruth_E0.tsv',\n",
    "    'CL_HG002_E1_sirv': 'HG002_E1_merged_sirv_sorted_groundtruth_E1.tsv',\n",
    "    'CL_HG002_E2_sirv': 'HG002_E2_merged_sirv_sorted_groundtruth_E2.tsv',\n",
    "    'CL_K562_E0_sirv': 'K562_E0_merged_sirv_sorted_groundtruth_E0.tsv',\n",
    "    'CL_K562_E1_sirv': 'K562_E1_merged_sirv_sorted_groundtruth_E1.tsv',\n",
    "    'CL_K562_E2_sirv': 'K562_E2_merged_sirv_sorted_groundtruth_E2.tsv',\n",
    "    'CL_UHRR_E0_sirv': 'UHRR_E0_merged_sirv_sorted_groundtruth_E0.tsv',\n",
    "    'CL_UHRR_E1_sirv': 'UHRR_E1_merged_sirv_sorted_groundtruth_E1.tsv',\n",
    "    'CL_UHRR_E2_sirv': 'UHRR_E2_merged_sirv_sorted_groundtruth_E2.tsv'\n",
    "}\n",
    "\n",
    "groundtruth_base_dir = 'references/2.sirvs_pb/quantification_ground_truth'\n",
    "\n",
    "# Function to read in a file and add a method column\n",
    "def read_file(file_name, method_name, transcript_col, count_col):\n",
    "    delim = ',' if file_name.endswith('.csv') else '\\t'\n",
    "    df = pd.read_csv(file_name, delimiter=delim)\n",
    "    df.columns = df.columns.str.lower()  # Convert column names to lowercase\n",
    "    transcript_col = transcript_col.lower()\n",
    "    count_col = count_col.lower()\n",
    "    \n",
    "    # Handle Bambu specific case\n",
    "    if method_name == 'bambu':\n",
    "        count_col = df.columns[2]  # Always use the third column for Bambu\n",
    "    \n",
    "    # Handle Gffcompare specific case\n",
    "    if method_name == 'gffcompare':\n",
    "        transcript_col = 'ref_id'\n",
    "        count_col = 'expression'\n",
    "    \n",
    "    try:\n",
    "        df = df[[transcript_col, count_col]].rename(columns={transcript_col: 'transcript_name', count_col: 'count'})\n",
    "    except KeyError:\n",
    "        print(f\"Columns {transcript_col} and {count_col} not found in {file_name}. Available columns: {df.columns}\")\n",
    "        return None\n",
    "    df['method'] = method_name\n",
    "    return df\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(predicted, actual):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# Function to calculate Mean Relative Difference\n",
    "def calculate_mrd(predicted, actual):\n",
    "    return np.mean(np.abs(predicted - actual) / actual)\n",
    "\n",
    "# Initialize lists to collect all metrics results and merged counts\n",
    "all_metrics_results = []\n",
    "all_raw_counts = []\n",
    "\n",
    "# Process each folder\n",
    "for folder in folders:\n",
    "    quant_dir = os.path.join(base_dir, folder, \"Quant\")\n",
    "    if not os.path.exists(quant_dir):\n",
    "        continue\n",
    "    \n",
    "    # Determine the ground truth file based on the folder\n",
    "    groundtruth_file = groundtruth_files[folder]\n",
    "    groundtruth_path = os.path.join(groundtruth_base_dir, groundtruth_file)\n",
    "    \n",
    "    # Read the ground truth file\n",
    "    groundtruth = pd.read_csv(groundtruth_path, delimiter='\\t')\n",
    "    groundtruth = groundtruth[['transcript_id', 'count']].rename(columns={'transcript_id': 'transcript_name'})\n",
    "    groundtruth['method'] = 'groundtruth'\n",
    "    \n",
    "    # Read all quantification files\n",
    "    data_frames = []\n",
    "    for file, method, transcript_col, count_col in zip(files, methods, transcript_cols, count_cols):\n",
    "        file_path = os.path.join(quant_dir, file)\n",
    "        if os.path.exists(file_path):\n",
    "            df = read_file(file_path, method, transcript_col, count_col)\n",
    "            if df is not None:\n",
    "                data_frames.append(df)\n",
    "    \n",
    "    # Combine all data frames into one\n",
    "    data = pd.concat(data_frames)\n",
    "    all_data = pd.concat([groundtruth, data])\n",
    "    all_data.fillna(0, inplace=True)\n",
    "    \n",
    "    # Ensure the count column contains only numeric values\n",
    "    all_data['count'] = pd.to_numeric(all_data['count'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Store raw counts for combined_merged_counts.tsv\n",
    "    raw_data = all_data.pivot(index='transcript_name', columns='method', values='count').fillna(0)\n",
    "    raw_data['Folder'] = folder\n",
    "    all_raw_counts.append(raw_data)\n",
    "    \n",
    "    all_data['count'] = np.log2(all_data['count'] + 1)\n",
    "    \n",
    "    # Reshape the data to wide format\n",
    "    all_data_wide = all_data.pivot(index='transcript_name', columns='method', values='count')\n",
    "    all_data_wide = all_data_wide[all_data_wide['groundtruth'].notna()]\n",
    "    \n",
    "    merged_data = all_data_wide.fillna(0)\n",
    "    \n",
    "    # Calculate metrics for each column against groundtruth, excluding non-numeric columns\n",
    "    for column_name in merged_data.columns:\n",
    "        if column_name != 'groundtruth':\n",
    "            rmse_value = calculate_rmse(merged_data[column_name], merged_data['groundtruth'])\n",
    "            if np.all(merged_data[column_name].iloc[:] == merged_data[column_name].iloc[0]):\n",
    "                pearson_value = spearman_value = np.nan\n",
    "            else:\n",
    "                pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
    "                spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
    "            mrd_value = calculate_mrd(merged_data[column_name], merged_data['groundtruth'])\n",
    "            all_metrics_results.append({\n",
    "                'Folder': folder,\n",
    "                'Tool': column_name,\n",
    "                'RMSE': rmse_value,\n",
    "                'Pearson_Correlation': pearson_value,\n",
    "                'Spearman_Correlation': spearman_value,\n",
    "                'Mean_Relative_Difference': mrd_value\n",
    "            })\n",
    "\n",
    "# Convert the collected metrics results to a DataFrame\n",
    "all_metrics_results_df = pd.DataFrame(all_metrics_results)\n",
    "\n",
    "# Save the combined metrics results to a TSV file\n",
    "combined_metrics_results_path = os.path.join(benchmarking_results_dir, 'combined_quantification_metrics_results.tsv')\n",
    "all_metrics_results_df.to_csv(combined_metrics_results_path, sep='\\t', index=False)\n",
    "\n",
    "# Combine all raw counts into a single DataFrame\n",
    "all_raw_counts_df = pd.concat(all_raw_counts)\n",
    "\n",
    "# Save the combined raw counts to a TSV file\n",
    "combined_merged_counts_path = os.path.join(benchmarking_results_dir, 'combined_quantification_merged_counts.tsv')\n",
    "all_raw_counts_df.to_csv(combined_merged_counts_path, sep='\\t')\n",
    "\n",
    "# Print the combined metrics results\n",
    "print(\"Combined Metrics Results:\")\n",
    "print(all_metrics_results_df)\n",
    "\n",
    "# Generate PDF with plots\n",
    "pdf_path = os.path.join(benchmarking_results_dir, 'combined_quantification_metrics_plots.pdf')\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for folder in folders:\n",
    "        folder_data = all_metrics_results_df[all_metrics_results_df['Folder'] == folder]\n",
    "        \n",
    "        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "        fig.suptitle(f'Metrics for {folder}', fontsize=16)\n",
    "        \n",
    "        # Sort data for plotting\n",
    "        folder_data_rmse = folder_data.sort_values(by='RMSE')\n",
    "        folder_data_mrd = folder_data.sort_values(by='Mean_Relative_Difference')\n",
    "        folder_data_pearson = folder_data.sort_values(by='Pearson_Correlation', ascending=False)\n",
    "        folder_data_spearman = folder_data.sort_values(by='Spearman_Correlation', ascending=False)\n",
    "        \n",
    "        # RMSE plot\n",
    "        axs[1, 0].bar(folder_data_rmse['Tool'], folder_data_rmse['RMSE'])\n",
    "        axs[1, 0].set_title('RMSE')\n",
    "        axs[1, 0].set_xticks(range(len(folder_data_rmse['Tool'])))\n",
    "        axs[1, 0].set_xticklabels(folder_data_rmse['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Pearson Correlation plot\n",
    "        axs[0, 0].bar(folder_data_pearson['Tool'], folder_data_pearson['Pearson_Correlation'])\n",
    "        axs[0, 0].set_title('Pearson Correlation')\n",
    "        axs[0, 0].set_xticks(range(len(folder_data_pearson['Tool'])))\n",
    "        axs[0, 0].set_xticklabels(folder_data_pearson['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Spearman Correlation plot\n",
    "        axs[0, 1].bar(folder_data_spearman['Tool'], folder_data_spearman['Spearman_Correlation'])\n",
    "        axs[0, 1].set_title('Spearman Correlation')\n",
    "        axs[0, 1].set_xticks(range(len(folder_data_spearman['Tool'])))\n",
    "        axs[0, 1].set_xticklabels(folder_data_spearman['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Mean Relative Difference plot\n",
    "        axs[1, 1].bar(folder_data_mrd['Tool'], folder_data_mrd['Mean_Relative_Difference'])\n",
    "        axs[1, 1].set_title('Mean Relative Difference')\n",
    "        axs[1, 1].set_xticks(range(len(folder_data_mrd['Tool'])))\n",
    "        axs[1, 1].set_xticklabels(folder_data_mrd['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"PDF with plots saved to {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cf9b2-9560-4839-85ec-19b2647bce80",
   "metadata": {},
   "source": [
    "#### MORFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee09a5b2-cc24-4f93-bf4b-489daba74320",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Metrics Results:\n",
      "                                       Folder        Tool      RMSE  \\\n",
      "0      morf2_ont_merged_annot_compat_1isoform       bambu  1.944429   \n",
      "1      morf2_ont_merged_annot_compat_1isoform       flair  2.270548   \n",
      "2      morf2_ont_merged_annot_compat_1isoform  gffcompare  1.805018   \n",
      "3      morf2_ont_merged_annot_compat_1isoform    isoquant  2.732091   \n",
      "4      morf2_ont_merged_annot_compat_1isoform   isosceles  1.630663   \n",
      "5      morf2_ont_merged_annot_compat_1isoform   lraa_0223  0.641843   \n",
      "6      morf2_ont_merged_annot_compat_1isoform     oarfish  0.702956   \n",
      "7      morf2_ont_merged_annot_compat_1isoform      salmon  1.787564   \n",
      "8      morf2_ont_merged_annot_compat_1isoform   stringtie  4.961009   \n",
      "9   morf2_pacbio_merged_annot_compat_1isoform       bambu  2.341029   \n",
      "10  morf2_pacbio_merged_annot_compat_1isoform       flair  3.019903   \n",
      "11  morf2_pacbio_merged_annot_compat_1isoform  gffcompare  2.116623   \n",
      "12  morf2_pacbio_merged_annot_compat_1isoform    isoquant  3.434034   \n",
      "13  morf2_pacbio_merged_annot_compat_1isoform   isosceles  2.066941   \n",
      "14  morf2_pacbio_merged_annot_compat_1isoform   lraa_0223  0.395152   \n",
      "15  morf2_pacbio_merged_annot_compat_1isoform     oarfish  0.768721   \n",
      "16  morf2_pacbio_merged_annot_compat_1isoform      salmon  1.762671   \n",
      "17  morf2_pacbio_merged_annot_compat_1isoform   stringtie  5.813836   \n",
      "\n",
      "    Pearson_Correlation  Spearman_Correlation  Mean_Relative_Difference  \n",
      "0              0.714616              0.847288                  0.104436  \n",
      "1              0.706047              0.799659                  0.160378  \n",
      "2              0.729342              0.832293                  0.125323  \n",
      "3              0.634660              0.752537                  0.188722  \n",
      "4              0.780836              0.816170                  0.118999  \n",
      "5              0.975114              0.983989                  0.079214  \n",
      "6              0.944355              0.943841                  0.061100  \n",
      "7              0.814396              0.789272                  0.215531  \n",
      "8              0.330165              0.566537                  0.717209  \n",
      "9              0.635891              0.852420                  0.075218  \n",
      "10             0.569851              0.788542                  0.128349  \n",
      "11             0.662874              0.842836                  0.083565  \n",
      "12             0.520543              0.754906                  0.151980  \n",
      "13             0.694086              0.761261                  0.101086  \n",
      "14             0.983020              0.990195                  0.013450  \n",
      "15             0.932030              0.929090                  0.037222  \n",
      "16             0.814368              0.776318                  0.148125  \n",
      "17             0.261546              0.542677                  0.596474  \n",
      "PDF with plots saved to benchmarking_results/3.morfs_pb_ont/combined_quantification_metrics_plots.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the base directory where your files are located\n",
    "base_dir = \"terra_outputs/3.morfs_pb_ont\"\n",
    "benchmarking_results_dir = \"benchmarking_results/3.morfs_pb_ont\"\n",
    "\n",
    "# Ensure the benchmarking results directory exists\n",
    "os.makedirs(benchmarking_results_dir, exist_ok=True)\n",
    "\n",
    "# Define the folders to process\n",
    "folders = [\n",
    "    \"morf2_ont_merged_annot_compat_1isoform\", \n",
    "    \"morf2_pacbio_merged_annot_compat_1isoform\"\n",
    "]\n",
    "\n",
    "# Define the file names, methods, transcript columns, and count columns\n",
    "files = [\n",
    "    'Bambu_quant.txt', 'Flair_quant.tsv', 'Isosceles_quant.txt', 'IsoQuant_quant.tsv', \n",
    "    'Oarfish_quant.tsv', 'Salmon_quant.sf', 'StringTie_quant.csv', \n",
    "    'LRAA_0223.quant-only.quant.expr', \n",
    "    'Gffcompare_OUT_expression_matrix.tsv'\n",
    "]\n",
    "\n",
    "methods = [\n",
    "    'bambu', 'flair', 'isosceles', 'isoquant', \n",
    "    'oarfish', 'salmon', 'stringtie', \n",
    "    'lraa_0223', \n",
    "    'gffcompare'\n",
    "]\n",
    "\n",
    "transcript_cols = [\n",
    "    'txname', 'ids', 'transcript_id', '#feature_id', 'tname', \n",
    "    'name', 'transcript_id', 'transcript_id', \n",
    "    'transcript_id', \n",
    "    'ref_id'\n",
    "]\n",
    "\n",
    "count_cols = [\n",
    "    '', 'flair_condition1_batch1', 'count', 'count', 'num_reads', \n",
    "    'numreads', 'stringtie', 'all_reads', \n",
    "    'all_reads', \n",
    "    'expression'\n",
    "]\n",
    "\n",
    "# Define the ground truth file paths\n",
    "groundtruth_files = {\n",
    "    'morf2_ont_merged_annot_compat_1isoform': 'references/3.morfs_pb_ont/ont/morf2_ont_merged_annot_compat_sorted_tn_counts.tsv',\n",
    "    'morf2_pacbio_merged_annot_compat_1isoform': 'references/3.morfs_pb_ont/pb/morf2_pacbio_merged_annot_compat_sorted_tn_counts.tsv'\n",
    "}\n",
    "\n",
    "# Function to read in a file and add a method column\n",
    "def read_file(file_name, method_name, transcript_col, count_col):\n",
    "    delim = ',' if file_name.endswith('.csv') else '\\t'\n",
    "    df = pd.read_csv(file_name, delimiter=delim)\n",
    "    df.columns = df.columns.str.lower()  # Convert column names to lowercase\n",
    "    transcript_col = transcript_col.lower()\n",
    "    count_col = count_col.lower()\n",
    "    \n",
    "    # Handle Bambu specific case\n",
    "    if method_name == 'bambu':\n",
    "        count_col = df.columns[2]  # Always use the third column for Bambu\n",
    "    \n",
    "    # Handle Gffcompare specific case\n",
    "    if method_name == 'gffcompare':\n",
    "        transcript_col = 'ref_id'\n",
    "        count_col = 'expression'\n",
    "    \n",
    "    try:\n",
    "        df = df[[transcript_col, count_col]].rename(columns={transcript_col: 'transcript_name', count_col: 'count'})\n",
    "    except KeyError:\n",
    "        print(f\"Columns {transcript_col} and {count_col} not found in {file_name}. Available columns: {df.columns}\")\n",
    "        return None\n",
    "    df['method'] = method_name\n",
    "    return df\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(predicted, actual):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# Function to calculate Mean Relative Difference\n",
    "def calculate_mrd(predicted, actual):\n",
    "    return np.mean(np.abs(predicted - actual) / actual)\n",
    "\n",
    "# Initialize lists to collect all metrics results and merged counts\n",
    "all_metrics_results = []\n",
    "all_raw_counts = []\n",
    "\n",
    "# Process each folder\n",
    "for folder in folders:\n",
    "    quant_dir = os.path.join(base_dir, folder, \"Quant\")\n",
    "    if not os.path.exists(quant_dir):\n",
    "        continue\n",
    "    \n",
    "    # Determine the ground truth file based on the folder\n",
    "    groundtruth_path = groundtruth_files[folder]\n",
    "    \n",
    "    # Read the ground truth file\n",
    "    groundtruth = pd.read_csv(groundtruth_path, delimiter='\\t')\n",
    "    groundtruth = groundtruth[['transcript_id', 'count']].rename(columns={'transcript_id': 'transcript_name'})\n",
    "    groundtruth['method'] = 'groundtruth'\n",
    "    \n",
    "    # Read all quantification files\n",
    "    data_frames = []\n",
    "    for file, method, transcript_col, count_col in zip(files, methods, transcript_cols, count_cols):\n",
    "        file_path = os.path.join(quant_dir, file)\n",
    "        if os.path.exists(file_path):\n",
    "            df = read_file(file_path, method, transcript_col, count_col)\n",
    "            if df is not None:\n",
    "                data_frames.append(df)\n",
    "    \n",
    "    # Combine all data frames into one\n",
    "    data = pd.concat(data_frames)\n",
    "    all_data = pd.concat([groundtruth, data])\n",
    "    all_data.fillna(0, inplace=True)\n",
    "    \n",
    "    # Ensure the count column contains only numeric values\n",
    "    all_data['count'] = pd.to_numeric(all_data['count'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Store raw counts for combined_merged_counts.tsv\n",
    "    raw_data = all_data.pivot(index='transcript_name', columns='method', values='count').fillna(0)\n",
    "    raw_data['Folder'] = folder\n",
    "    all_raw_counts.append(raw_data)\n",
    "    \n",
    "    all_data['count'] = np.log2(all_data['count'] + 1)\n",
    "    \n",
    "    # Reshape the data to wide format\n",
    "    all_data_wide = all_data.pivot(index='transcript_name', columns='method', values='count')\n",
    "    all_data_wide = all_data_wide[all_data_wide['groundtruth'].notna()]\n",
    "    \n",
    "    merged_data = all_data_wide.fillna(0)\n",
    "    \n",
    "    # Calculate metrics for each column against groundtruth, excluding non-numeric columns\n",
    "    for column_name in merged_data.columns:\n",
    "        if column_name != 'groundtruth':\n",
    "            rmse_value = calculate_rmse(merged_data[column_name], merged_data['groundtruth'])\n",
    "            if np.all(merged_data[column_name].iloc[:] == merged_data[column_name].iloc[0]):\n",
    "                pearson_value = spearman_value = np.nan\n",
    "            else:\n",
    "                pearson_value, _ = pearsonr(merged_data[column_name], merged_data['groundtruth'])\n",
    "                spearman_value, _ = spearmanr(merged_data[column_name], merged_data['groundtruth'])\n",
    "            mrd_value = calculate_mrd(merged_data[column_name], merged_data['groundtruth'])\n",
    "            all_metrics_results.append({\n",
    "                'Folder': folder,\n",
    "                'Tool': column_name,\n",
    "                'RMSE': rmse_value,\n",
    "                'Pearson_Correlation': pearson_value,\n",
    "                'Spearman_Correlation': spearman_value,\n",
    "                'Mean_Relative_Difference': mrd_value\n",
    "            })\n",
    "\n",
    "# Convert the collected metrics results to a DataFrame\n",
    "all_metrics_results_df = pd.DataFrame(all_metrics_results)\n",
    "\n",
    "# Save the combined metrics results to a TSV file\n",
    "combined_metrics_results_path = os.path.join(benchmarking_results_dir, 'combined_quantification_metrics_results.tsv')\n",
    "all_metrics_results_df.to_csv(combined_metrics_results_path, sep='\\t', index=False)\n",
    "\n",
    "# Combine all raw counts into a single DataFrame\n",
    "all_raw_counts_df = pd.concat(all_raw_counts)\n",
    "\n",
    "# Save the combined raw counts to a TSV file\n",
    "combined_merged_counts_path = os.path.join(benchmarking_results_dir, 'combined_quantification_merged_counts.tsv')\n",
    "all_raw_counts_df.to_csv(combined_merged_counts_path, sep='\\t')\n",
    "\n",
    "# Print the combined metrics results\n",
    "print(\"Combined Metrics Results:\")\n",
    "print(all_metrics_results_df)\n",
    "\n",
    "# Generate PDF with plots\n",
    "pdf_path = os.path.join(benchmarking_results_dir, 'combined_quantification_metrics_plots.pdf')\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for folder in folders:\n",
    "        folder_data = all_metrics_results_df[all_metrics_results_df['Folder'] == folder]\n",
    "        \n",
    "        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "        fig.suptitle(f'Metrics for {folder}', fontsize=16)\n",
    "        \n",
    "        # Sort data for plotting\n",
    "        folder_data_rmse = folder_data.sort_values(by='RMSE')\n",
    "        folder_data_mrd = folder_data.sort_values(by='Mean_Relative_Difference')\n",
    "        folder_data_pearson = folder_data.sort_values(by='Pearson_Correlation', ascending=False)\n",
    "        folder_data_spearman = folder_data.sort_values(by='Spearman_Correlation', ascending=False)\n",
    "        \n",
    "        # RMSE plot\n",
    "        axs[1, 0].bar(folder_data_rmse['Tool'], folder_data_rmse['RMSE'])\n",
    "        axs[1, 0].set_title('RMSE')\n",
    "        axs[1, 0].set_xticks(range(len(folder_data_rmse['Tool'])))\n",
    "        axs[1, 0].set_xticklabels(folder_data_rmse['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Pearson Correlation plot\n",
    "        axs[0, 0].bar(folder_data_pearson['Tool'], folder_data_pearson['Pearson_Correlation'])\n",
    "        axs[0, 0].set_title('Pearson Correlation')\n",
    "        axs[0, 0].set_xticks(range(len(folder_data_pearson['Tool'])))\n",
    "        axs[0, 0].set_xticklabels(folder_data_pearson['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Spearman Correlation plot\n",
    "        axs[0, 1].bar(folder_data_spearman['Tool'], folder_data_spearman['Spearman_Correlation'])\n",
    "        axs[0, 1].set_title('Spearman Correlation')\n",
    "        axs[0, 1].set_xticks(range(len(folder_data_spearman['Tool'])))\n",
    "        axs[0, 1].set_xticklabels(folder_data_spearman['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        # Mean Relative Difference plot\n",
    "        axs[1, 1].bar(folder_data_mrd['Tool'], folder_data_mrd['Mean_Relative_Difference'])\n",
    "        axs[1, 1].set_title('Mean Relative Difference')\n",
    "        axs[1, 1].set_xticks(range(len(folder_data_mrd['Tool'])))\n",
    "        axs[1, 1].set_xticklabels(folder_data_mrd['Tool'], rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"PDF with plots saved to {pdf_path}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "mas_seq",
   "name": "tf2-cpu.2-13.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-13:m111"
  },
  "kernelspec": {
   "display_name": "mas_seq",
   "language": "python",
   "name": "mas_seq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
