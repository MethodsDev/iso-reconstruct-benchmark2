{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba6d0a9-6af5-4c40-8dd4-f0cdeb39dac9",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged parameters\n",
    "\n",
    "PYLIB_DIR = None\n",
    "\n",
    "########################\n",
    "# inputs for quant-only\n",
    "########################\n",
    "\n",
    "# Reference info\n",
    "REF_gtf_file = None\n",
    "REF_quant_file = None\n",
    "\n",
    "# Predictions\n",
    "FLAMES_gtf_file = None\n",
    "FLAMES_quant_file = None\n",
    "\n",
    "IsoQuant_quant_file = None\n",
    "\n",
    "IsoSeq_gtf_file = None\n",
    "IsoSeq_quant_file = None\n",
    "\n",
    "LRAA_quant_file = None\n",
    "\n",
    "Mandalorion_gtf_file = None\n",
    "Mandalorion_quant_file = None\n",
    "\n",
    "Oarfish_align_quant_file = None\n",
    "\n",
    "Oarfish_reads_quant_file = None\n",
    "\n",
    "Bambu_quant_file = None\n",
    "\n",
    "ESPRESSO_quant_file = None\n",
    "\n",
    "FLAIR_quant_file = None\n",
    "\n",
    "Isosceles_gtf_file = None\n",
    "Isosceles_quant_file = None\n",
    "\n",
    "StringTie_quant_file = None\n",
    "\n",
    "TALON_gtf_file = None\n",
    "TALON_quant_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245d2b2-3be4-41ce-9936-33187e158a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "sys.path.insert(0, PYLIB_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3a20f-74a7-4556-bd9c-eb67e6029a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import BenchmarkingRoutines\n",
    "from importlib import reload\n",
    "reload(BenchmarkingRoutines)\n",
    "from BenchmarkingRoutines import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc1d73-7595-4b3c-8d67-1107abeb9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c64a1-dbba-4d8f-a0fa-679d7fcdea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors for plots\n",
    "set_color_palette(\"FLAMES\", \"gainsboro\", \"solid\")\n",
    "set_color_palette(\"IsoQuant\", \"blue\", \"solid\")\n",
    "set_color_palette(\"IsoSeq\", \"orchid\", \"solid\")\n",
    "set_color_palette(\"LRAA\", \"teal\", \"solid\")\n",
    "set_color_palette(\"Mandalorion\", \"lightblue\", \"solid\")\n",
    "set_color_palette(\"Oarfish_align\", \"khaki\", \"solid\")\n",
    "set_color_palette(\"Oarfish_reads\", \"peachpuff\", \"solid\")\n",
    "set_color_palette(\"Bambu\", \"forestgreen\", \"solid\")\n",
    "set_color_palette(\"ESPRESSO\", \"brown\", \"solid\")\n",
    "set_color_palette(\"FLAIR\", \"pink\", \"solid\")\n",
    "set_color_palette(\"Isosceles\", \"red\", \"solid\")\n",
    "set_color_palette(\"StringTie\", \"aquamarine\", \"solid\")\n",
    "set_color_palette(\"TALON\", \"orange\", \"solid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ba242-ef90-4fea-8f6f-2c2ec5780cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_only_dir = \"processed_prog_results\"\n",
    "\n",
    "prog_quant_files = {  \n",
    "    \"FLAMES\" : [FLAMES_quant_file, FLAMES_gtf_file],\n",
    "    \"IsoQuant\" : [IsoQuant_quant_file, REF_gtf_file],\n",
    "    \"IsoSeq\" : [IsoSeq_quant_file, IsoSeq_gtf_file],\n",
    "    \"LRAA\" : [LRAA_quant_file, REF_gtf_file ],\n",
    "    \"Mandalorion\" : [Mandalorion_quant_file, Mandalorion_gtf_file],\n",
    "    \"Oarfish_align\" : [Oarfish_align_quant_file, REF_gtf_file],\n",
    "    \"Oarfish_reads\" : [Oarfish_reads_quant_file, REF_gtf_file],\n",
    "    \"ESPRESSO\" : [ESPRESSO_quant_file, REF_gtf_file],\n",
    "    \"FLAIR\" : [FLAIR_quant_file, REF_gtf_file],\n",
    "    \"Isosceles\" : [Isosceles_quant_file, Isosceles_gtf_file],\n",
    "    \"Bambu\" : [Bambu_quant_file, REF_gtf_file],\n",
    "    \"StringTie\" : [StringTie_quant_file, REF_gtf_file],\n",
    "    \"TALON\" : [TALON_quant_file, TALON_gtf_file]\n",
    "}\n",
    "\n",
    "\n",
    "fullQuantsDf_dict = {}\n",
    "for progname, (tsv_fname, gtf_fname) in prog_quant_files.items():\n",
    "    if tsv_fname is None:\n",
    "        continue\n",
    "\n",
    "    print(progname, tsv_fname, gtf_fname)\n",
    "    fullQuantsDf_dict[progname] = indexDfByIntronId(parseGTFtoIntronIDsandQuants(gtf_fname, tsv_fname))\n",
    "\n",
    "\n",
    "progname_to_i_sample_df_dict_to_tsv(fullQuantsDf_dict, \"progname_to_IntronId_expr_vals.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd6b28-834e-47fd-a862-fcf948231d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Step 1: Build the expression matrix from your dictionary\n",
    "def build_expression_matrix(fullQuantsDf_dict):\n",
    "    \"\"\"\n",
    "    Build an expression matrix from a dictionary of dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    fullQuantsDf_dict: dict with program names as keys and pandas DataFrames as values\n",
    "                      DataFrames should be indexed by intronIds and contain a 'tpm' column\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Expression matrix with intronIds as rows and program names as columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract TPM values for each program\n",
    "    tpm_data = {}\n",
    "    \n",
    "    for program_name, df in fullQuantsDf_dict.items():\n",
    "        # Extract the tpm column and use the index (intronIds) as the row identifier\n",
    "        tpm_data[program_name] = df['tpm']\n",
    "    \n",
    "    # Create the expression matrix\n",
    "    expression_matrix = pd.DataFrame(tpm_data)\n",
    "    \n",
    "    # Fill any missing values with 0 (in case some intronIds are missing in some programs)\n",
    "    expression_matrix = expression_matrix.fillna(0)\n",
    "    \n",
    "    return expression_matrix\n",
    "\n",
    "# Step 2: Calculate correlation matrix\n",
    "def calculate_correlation_matrix(expression_matrix, method='pearson', log_transform=False):\n",
    "    \"\"\"\n",
    "    Calculate correlation matrix between programs based on TPM expression levels.\n",
    "    \n",
    "    Parameters:\n",
    "    expression_matrix: pandas.DataFrame with intronIds as rows and programs as columns\n",
    "    method: str, correlation method ('pearson', 'spearman', 'kendall')\n",
    "    log_transform: bool, if True apply log(x+1) transformation before correlation calculation\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Correlation matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply log transformation if requested\n",
    "    if log_transform:\n",
    "        print(\"Applying log(x+1) transformation to expression values...\")\n",
    "        # Apply log(x+1) transformation to handle zero values\n",
    "        transformed_matrix = np.log1p(expression_matrix)\n",
    "        print(f\"Original expression range: {expression_matrix.min().min():.4f} to {expression_matrix.max().max():.4f}\")\n",
    "        print(f\"Log-transformed range: {transformed_matrix.min().min():.4f} to {transformed_matrix.max().max():.4f}\")\n",
    "    else:\n",
    "        transformed_matrix = expression_matrix\n",
    "    \n",
    "    # Calculate correlation between programs (columns)\n",
    "    correlation_matrix = transformed_matrix.corr(method=method)\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "# Step 3: Visualize the correlation matrix\n",
    "def plot_correlation_heatmap(correlation_matrix, figsize=(10, 8), title='Program Expression Correlation'):\n",
    "    \"\"\"\n",
    "    Create a heatmap of the correlation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    correlation_matrix: pandas.DataFrame, correlation matrix\n",
    "    figsize: tuple, figure size\n",
    "    title: str, plot title\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                annot=True,           # Show correlation values\n",
    "                cmap='coolwarm',      # Color scheme\n",
    "                center=0,             # Center colormap at 0\n",
    "                square=True,          # Make cells square\n",
    "                fmt='.3f',            # Format numbers to 3 decimal places\n",
    "                cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    \n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.xlabel('Programs', fontsize=12)\n",
    "    plt.ylabel('Programs', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Step 5: Dendrogram plotting functions\n",
    "def plot_dendrogram(correlation_matrix, method='average', metric='correlation', \n",
    "                   figsize=(12, 8), title='Program Clustering Dendrogram'):\n",
    "    \"\"\"\n",
    "    Plot a dendrogram based on correlation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    correlation_matrix: pandas.DataFrame, correlation matrix between programs\n",
    "    method: str, linkage method ('average', 'single', 'complete', 'ward')\n",
    "    metric: str, distance metric ('correlation', 'euclidean', 'cosine')\n",
    "    figsize: tuple, figure size\n",
    "    title: str, plot title\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert correlation to distance\n",
    "    if metric == 'correlation':\n",
    "        # Distance = 1 - correlation (for positive correlations)\n",
    "        # For negative correlations, we use 1 - |correlation| to maintain distance properties\n",
    "        distance_matrix = 1 - np.abs(correlation_matrix)\n",
    "        # Ensure diagonal is 0 (distance from program to itself)\n",
    "        np.fill_diagonal(distance_matrix.values, 0)\n",
    "    else:\n",
    "        # For other metrics, we'll use the correlation values directly\n",
    "        # and let scipy handle the distance calculation\n",
    "        distance_matrix = correlation_matrix\n",
    "    \n",
    "    # Convert to condensed distance matrix for linkage\n",
    "    if metric == 'correlation':\n",
    "        # We already have the distance matrix, convert to condensed form\n",
    "        condensed_distances = squareform(distance_matrix, checks=False)\n",
    "        # Perform hierarchical clustering\n",
    "        linkage_matrix = linkage(condensed_distances, method=method)\n",
    "    else:\n",
    "        # Use the correlation matrix directly and let scipy calculate distances\n",
    "        linkage_matrix = linkage(correlation_matrix.values, method=method, metric=metric)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Plot dendrogram\n",
    "    dendro = dendrogram(linkage_matrix, \n",
    "                       labels=correlation_matrix.columns,\n",
    "                       orientation='top',\n",
    "                       leaf_rotation=45,\n",
    "                       leaf_font_size=10)\n",
    "    \n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.xlabel('Programs', fontsize=12)\n",
    "    plt.ylabel('Distance', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return linkage_matrix, dendro\n",
    "\n",
    "def plot_dendrogram_with_heatmap(correlation_matrix, method='average', \n",
    "                                figsize=(15, 10), title='Clustered Expression Correlation'):\n",
    "    \"\"\"\n",
    "    Plot dendrogram alongside a reordered correlation heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "    correlation_matrix: pandas.DataFrame, correlation matrix\n",
    "    method: str, linkage method\n",
    "    figsize: tuple, figure size\n",
    "    title: str, plot title\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate linkage\n",
    "    distance_matrix = 1 - np.abs(correlation_matrix)\n",
    "    np.fill_diagonal(distance_matrix.values, 0)\n",
    "    condensed_distances = squareform(distance_matrix, checks=False)\n",
    "    linkage_matrix = linkage(condensed_distances, method=method)\n",
    "    \n",
    "    # Create clustered heatmap using seaborn\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Use seaborn's clustermap which automatically handles the dendrogram and reordering\n",
    "    clustered_heatmap = sns.clustermap(correlation_matrix,\n",
    "                                      method=method,\n",
    "                                      metric='correlation',\n",
    "                                      annot=True,\n",
    "                                      cmap='coolwarm',\n",
    "                                      center=0,\n",
    "                                      square=True,\n",
    "                                      fmt='.3f',\n",
    "                                      figsize=figsize,\n",
    "                                      cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    \n",
    "    clustered_heatmap.fig.suptitle(title, fontsize=14, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the reordered correlation matrix\n",
    "    reordered_index = clustered_heatmap.dendrogram_row.reordered_ind\n",
    "    reordered_columns = correlation_matrix.columns[reordered_index]\n",
    "    reordered_correlation = correlation_matrix.loc[reordered_columns, reordered_columns]\n",
    "    \n",
    "    return reordered_correlation, linkage_matrix\n",
    "\n",
    "def get_clusters(correlation_matrix, method='average', n_clusters=None, distance_threshold=None):\n",
    "    \"\"\"\n",
    "    Get cluster assignments for programs based on correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    correlation_matrix: pandas.DataFrame, correlation matrix\n",
    "    method: str, linkage method\n",
    "    n_clusters: int, number of clusters to form (alternative to distance_threshold)\n",
    "    distance_threshold: float, distance threshold for forming clusters\n",
    "    \n",
    "    Returns:\n",
    "    pandas.Series: cluster assignments for each program\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate linkage\n",
    "    distance_matrix = 1 - np.abs(correlation_matrix)\n",
    "    np.fill_diagonal(distance_matrix.values, 0)\n",
    "    condensed_distances = squareform(distance_matrix, checks=False)\n",
    "    linkage_matrix = linkage(condensed_distances, method=method)\n",
    "    \n",
    "    # Get cluster assignments\n",
    "    if n_clusters is not None:\n",
    "        clusters = fcluster(linkage_matrix, n_clusters, criterion='maxclust')\n",
    "    elif distance_threshold is not None:\n",
    "        clusters = fcluster(linkage_matrix, distance_threshold, criterion='distance')\n",
    "    else:\n",
    "        # Default: use distance threshold of 0.5 (corresponding to correlation of 0.5)\n",
    "        clusters = fcluster(linkage_matrix, 0.5, criterion='distance')\n",
    "    \n",
    "    # Create a pandas Series with program names as index\n",
    "    cluster_assignments = pd.Series(clusters, index=correlation_matrix.columns, name='Cluster')\n",
    "    \n",
    "    return cluster_assignments\n",
    "\n",
    "def analyze_clusters(cluster_assignments, correlation_matrix):\n",
    "    \"\"\"\n",
    "    Analyze the characteristics of each cluster.\n",
    "    \n",
    "    Parameters:\n",
    "    cluster_assignments: pandas.Series, cluster assignments\n",
    "    correlation_matrix: pandas.DataFrame, correlation matrix\n",
    "    \n",
    "    Returns:\n",
    "    dict: cluster analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster_analysis = {}\n",
    "    \n",
    "    for cluster_id in np.unique(cluster_assignments):\n",
    "        # Get programs in this cluster\n",
    "        programs_in_cluster = cluster_assignments[cluster_assignments == cluster_id].index.tolist()\n",
    "        \n",
    "        # Calculate within-cluster correlations\n",
    "        if len(programs_in_cluster) > 1:\n",
    "            cluster_corr_matrix = correlation_matrix.loc[programs_in_cluster, programs_in_cluster]\n",
    "            # Get upper triangle to avoid duplicates and diagonal\n",
    "            mask = np.triu(np.ones_like(cluster_corr_matrix, dtype=bool), k=1)\n",
    "            within_cluster_corrs = cluster_corr_matrix.where(mask).stack().values\n",
    "            \n",
    "            cluster_analysis[cluster_id] = {\n",
    "                'programs': programs_in_cluster,\n",
    "                'size': len(programs_in_cluster),\n",
    "                'mean_within_correlation': np.mean(within_cluster_corrs),\n",
    "                'min_within_correlation': np.min(within_cluster_corrs),\n",
    "                'max_within_correlation': np.max(within_cluster_corrs)\n",
    "            }\n",
    "        else:\n",
    "            cluster_analysis[cluster_id] = {\n",
    "                'programs': programs_in_cluster,\n",
    "                'size': 1,\n",
    "                'mean_within_correlation': np.nan,\n",
    "                'min_within_correlation': np.nan,\n",
    "                'max_within_correlation': np.nan\n",
    "            }\n",
    "    \n",
    "    return cluster_analysis\n",
    "def get_correlation_summary(correlation_matrix):\n",
    "    \"\"\"\n",
    "    Get summary statistics of the correlation matrix.\n",
    "    \"\"\"\n",
    "    # Get upper triangle of correlation matrix (excluding diagonal)\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "    upper_triangle = correlation_matrix.where(mask)\n",
    "    \n",
    "    correlations = upper_triangle.stack().values\n",
    "    \n",
    "    summary = {\n",
    "        'mean_correlation': np.mean(correlations),\n",
    "        'median_correlation': np.median(correlations),\n",
    "        'std_correlation': np.std(correlations),\n",
    "        'min_correlation': np.min(correlations),\n",
    "        'max_correlation': np.max(correlations)\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def find_highly_correlated_pairs(correlation_matrix, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Find pairs of programs with correlation above threshold.\n",
    "    \"\"\"\n",
    "    # Get upper triangle to avoid duplicates\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "    upper_triangle = correlation_matrix.where(mask)\n",
    "    \n",
    "    # Find correlations above threshold\n",
    "    high_corr = upper_triangle.stack()\n",
    "    high_corr_pairs = high_corr[abs(high_corr) >= threshold].sort_values(ascending=False)\n",
    "    \n",
    "    return high_corr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11bf3d4-ba81-4231-8777-3eaac0e6f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution example:\n",
    "\n",
    "# Build expression matrix\n",
    "expression_matrix = build_expression_matrix(fullQuantsDf_dict)\n",
    "\n",
    "print(f\"Expression matrix shape: {expression_matrix.shape}\")\n",
    "print(f\"Number of introns: {expression_matrix.shape[0]}\")\n",
    "print(f\"Number of programs: {expression_matrix.shape[1]}\")\n",
    "print(\"\\nFirst few rows and columns:\")\n",
    "print(expression_matrix.iloc[:5, :5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a207e-3a17-4215-b8a8-092dab0d15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = calculate_correlation_matrix(expression_matrix, method='pearson', log_transform=True)\n",
    "\n",
    "print(f\"\\nCorrelation matrix shape: {correlation_matrix.shape}\")\n",
    "print(\"\\nCorrelation matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e63e0-a53f-4f44-a2e8-b183a78a4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation heatmap\n",
    "plot_correlation_heatmap(correlation_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9c5ff-f0c6-48ff-92d3-86519df75ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation summary\n",
    "summary = get_correlation_summary(correlation_matrix)\n",
    "print(\"\\nCorrelation Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898af4e4-fafb-4c5c-a879-43c75bf99bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly correlated pairs\n",
    "high_corr_pairs = find_highly_correlated_pairs(correlation_matrix, threshold=0.8)\n",
    "if not high_corr_pairs.empty:\n",
    "    print(f\"\\nHighly correlated pairs (|r| >= 0.8):\")\n",
    "    for (prog1, prog2), corr in high_corr_pairs.items():\n",
    "        print(f\"{prog1} - {prog2}: {corr:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo highly correlated pairs found (threshold = 0.8)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c6303-6dd5-4925-8479-ef306a63c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple dendrogram\n",
    "print(\"\\nPlotting dendrogram...\")\n",
    "linkage_matrix, dendro = plot_dendrogram(correlation_matrix, method='average')\n",
    "\n",
    "# Dendrogram with clustered heatmap\n",
    "print(\"\\nPlotting clustered heatmap with dendrograms...\")\n",
    "reordered_correlation, _ = plot_dendrogram_with_heatmap(correlation_matrix, method='average')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e9d49-b2f8-4ed5-87e9-8dd6c641200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster assignments\n",
    "print(\"\\nAnalyzing clusters...\")\n",
    "cluster_assignments = get_clusters(correlation_matrix, method='average', distance_threshold=0.5)\n",
    "print(f\"\\nCluster assignments:\")\n",
    "for program, cluster in cluster_assignments.items():\n",
    "    print(f\"  {program}: Cluster {cluster}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3881a5-3f41-44b3-9760-56303b6b1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clusters\n",
    "cluster_analysis = analyze_clusters(cluster_assignments, correlation_matrix)\n",
    "print(f\"\\nCluster Analysis:\")\n",
    "for cluster_id, analysis in cluster_analysis.items():\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    print(f\"  Size: {analysis['size']} programs\")\n",
    "    print(f\"  Programs: {', '.join(analysis['programs'])}\")\n",
    "    if analysis['size'] > 1:\n",
    "        print(f\"  Mean within-cluster correlation: {analysis['mean_within_correlation']:.4f}\")\n",
    "        print(f\"  Min within-cluster correlation: {analysis['min_within_correlation']:.4f}\")\n",
    "        print(f\"  Max within-cluster correlation: {analysis['max_within_correlation']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766011d9-c2d9-419d-86b0-595ec233078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative clustering with different number of clusters\n",
    "print(f\"\\n\" + \"-\"*30)\n",
    "print(\"Alternative clustering (4 clusters):\")\n",
    "cluster_assignments_4 = get_clusters(correlation_matrix, method='average', n_clusters=4)\n",
    "for program, cluster in cluster_assignments_4.items():\n",
    "    print(f\"  {program}: Cluster {cluster}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b62f9f-6b69-47fd-a5f9-512d0199ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "expression_matrix.to_csv('expression_matrix.csv')\n",
    "correlation_matrix.to_csv('correlation_matrix.csv')\n",
    "cluster_assignments.to_csv('cluster_assignments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
